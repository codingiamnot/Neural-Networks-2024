{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK9Wqqsd6cQ/2+U8VUsh/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codingiamnot/Neural-Networks-2024/blob/main/lab2/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "collapsed": true,
        "id": "znaZa_hQeZC6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "def download_mnist(is_train: bool):\n",
        "    dataset = MNIST(root=\"./data\",\n",
        "        transform=lambda x: np.array(x).flatten(),\n",
        "        download=True,\n",
        "        train=is_train)\n",
        "\n",
        "    mnist_data = []\n",
        "    mnist_labels = []\n",
        "\n",
        "    for image, label in dataset:\n",
        "        mnist_data.append(image)\n",
        "        mnist_labels.append(label)\n",
        "\n",
        "    return mnist_data, mnist_labels\n",
        "\n",
        "\n",
        "train_X, train_Y = download_mnist(True)\n",
        "test_X, test_Y = download_mnist(False)\n",
        "\n",
        "train_X = np.array(train_X)\n",
        "train_Y = np.array(train_Y)\n",
        "test_X = np.array(test_X)\n",
        "test_Y = np.array(test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the input data\n",
        "\n",
        "train_X = np.divide(train_X, 256)\n",
        "test_X = np.divide(test_X, 256)\n",
        "\n",
        "#conver ouput to one hot encoding\n",
        "\n",
        "def oneHot(value):\n",
        "  ans = np.zeros(10,)\n",
        "  ans[value] = 1\n",
        "  return ans\n",
        "\n",
        "train_Y = np.array([oneHot(value) for value in train_Y])\n",
        "test_Y = np.array([oneHot(value) for value in test_Y])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rIN2ZSE58Z8i"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return np.array([np.exp(line) / np.sum(np.exp(line)) for line in x])\n",
        "\n",
        "def get_predictions(x):\n",
        "  return np.argmax(x, axis=1)\n",
        "\n",
        "def run_on_batch(x, W, b):\n",
        "  ans = np.dot(x, W) + b\n",
        "  ans = softmax(ans)\n",
        "  return ans\n",
        "\n",
        "def update(input_x, true_y, pred_y, learning_rate, W, b):\n",
        "  W += learning_rate * np.dot(input_x.T, true_y - pred_y)\n",
        "  b += learning_rate * np.sum(true_y - pred_y, axis=0)"
      ],
      "metadata": {
        "id": "ruhm9AM5Q2zr"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(x, y, W, b):\n",
        "  pred_y = run_on_batch(x, W, b)\n",
        "  predictions = np.argmax(pred_y, axis=1)\n",
        "  labels = np.argmax(y, axis=1)\n",
        "\n",
        "  ans = 0\n",
        "  for i in range(0, len(predictions)):\n",
        "    if predictions[i] == labels[i]:\n",
        "      ans += 1\n",
        "\n",
        "  return ans / len(predictions)"
      ],
      "metadata": {
        "id": "AM4oMKGV-Mj1"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize\n",
        "\n",
        "W = np.random.rand(784, 10)\n",
        "b = np.zeros((10,))\n",
        "\n",
        "print(\"acc before training\", accuracy(test_X, test_Y, W, b))\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "while epochs > 0:\n",
        "  epochs -= 1\n",
        "\n",
        "  permutation = np.random.permutation(train_X.shape[0])\n",
        "  train_X = train_X[permutation]\n",
        "  train_Y = train_Y[permutation]\n",
        "\n",
        "  for i in range(0, train_X.shape[0], batch_size):\n",
        "    x_batch = train_X[i:i+batch_size]\n",
        "    y_batch = train_Y[i:i+batch_size]\n",
        "\n",
        "    y_pred = run_on_batch(x_batch, W, b)\n",
        "\n",
        "    update(x_batch, y_batch, y_pred, learning_rate, W, b)"
      ],
      "metadata": {
        "id": "fZlkXUY0RNLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c8b8ac-379f-45f5-a9ff-a652b3ea209b"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc before training 0.1412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(test_X, test_Y, W, b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw2QxAl8gFDT",
        "outputId": "d2faaa43-5616-45c9-a7aa-eb3225f40a6f"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9181\n"
          ]
        }
      ]
    }
  ]
}